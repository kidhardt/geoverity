{
  "common": {
    "skipToMain": "Skip to main content",
    "menu": "Menu",
    "closeMenu": "Close menu",
    "navigationOpened": "Navigation menu opened",
    "navigationClosed": "Navigation menu closed"
  },
  "nav": {
    "home": "Home",
    "services": "Services",
    "insights": "Insights",
    "contact": "Contact"
  },
  "languageSwitcher": {
    "label": "Language",
    "english": "English",
    "spanish": "Espa√±ol"
  },
  "homepage": {
    "heroHeading": "Protecting Academic Integrity in the AI Era",
    "heroSubheading": "We help universities maintain trust in student work and research. Build AI policies that work without starting an arms race.",
    "heroCta": "Explore Our Services",
    "missionHeading": "Our Mission",
    "missionText": "We partner with universities to build academic integrity frameworks. Faculty learn to assess student work in AI environments. Institutions maintain standards while adopting AI responsibly."
  },
  "insightsHub": {
    "heroHeading": "Insights",
    "heroSubheading": "Exploring graduate education, epistemic responsibility, and AI use in academia.",
    "noPosts": "No posts available yet. Check back soon.",
    "categories": "Categories",
    "allPosts": "All Posts"
  },
  "insightsPosts": {
    "trustCurrency": {
      "title": "Why Trust is the New Academic Currency",
      "slug": "why-trust-is-the-new-academic-currency",
      "excerpt": "Universities face a credibility crisis. Graduate programs need frameworks that demonstrate trustworthiness to prospective students and donors.",
      "content": "Universities competing for enrollment and funding now differentiate themselves through trust credentials. Graduate programs that document rigorous academic integrity frameworks attract students concerned about credential value. Administrators position integrity policies as competitive advantages rather than compliance burdens. Institutions that build systematic trust verification gain leverage in markets where reputation determines viability. Faculty who understand this shift advocate for integrity investments that strengthen institutional positioning.",
      "category": "academic-integrity",
      "readMoreLink": "/higher-education-consulting/trust-as-currency/",
      "readMoreText": "Learn how to position trust as institutional currency",
      "ctaText": "Schedule a consultation to discuss your trust framework"
    },
    "authorizedLLMs": {
      "title": "Authorized LLMs in Graduate Education",
      "slug": "authorized-llms-graduate-education",
      "excerpt": "Graduate students need AI tools that comply with data protection regulations while supporting legitimate research activities.",
      "content": "Departments deploy approved language models within institutional boundaries to maintain FERPA and GDPR compliance. Students access AI tools without exposing thesis data or research findings to external vendors. Faculty gain oversight of AI tool usage patterns without relying on detection software. Universities control which models operate on campus networks and how student data flows through systems. Authorized LLM deployments resolve tension between AI adoption and privacy protection.",
      "category": "academic-integrity",
      "readMoreLink": "/higher-education-consulting/authorized-departmental-llms/",
      "readMoreText": "Explore authorized LLM deployment options",
      "ctaText": "Contact us about secure departmental AI tools"
    }
  },
  "insightsCategories": {
    "academicIntegrity": {
      "name": "Academic Integrity",
      "description": "Graduate education, authorized AI tools, and building trust frameworks for student work.",
      "heroHeading": "Academic Integrity",
      "heroSubheading": "Exploring how universities maintain trust in student work while adopting AI tools responsibly."
    },
    "aiGovernance": {
      "name": "AI Governance",
      "description": "Policy frameworks, disclosure requirements, and institutional governance for AI adoption.",
      "heroHeading": "AI Governance",
      "heroSubheading": "Building policy frameworks that manage AI risk while enabling innovation."
    },
    "multilingualData": {
      "name": "Multilingual Data",
      "description": "Dataset bias, language diversity, and ethical considerations in AI training data.",
      "heroHeading": "Multilingual Data",
      "heroSubheading": "Addressing bias and quality in AI training data across languages and cultures."
    },
    "trustEvaluation": {
      "name": "Trust and Evaluation",
      "description": "Model evaluation, bias audits, fairness testing, and trustworthy AI metrics.",
      "heroHeading": "Trust and Evaluation",
      "heroSubheading": "Independent evaluation of AI model performance, fairness, and compliance."
    },
    "researchIntegrity": {
      "name": "Research Integrity",
      "description": "Research transparency, p-value interpretation, reproducibility, and statistical rigor.",
      "heroHeading": "Research Integrity",
      "heroSubheading": "Tools and practices for maintaining transparency and reproducibility in research."
    }
  },
  "servicesHub": {
    "heroHeading": "Our Services",
    "heroSubheading": "[Insert sentence here about AI data services for LLM development]",
    "dataCollectionHeading": "Data Collection & Enhancement",
    "dataCollectionDesc": "[Insert sentence here about curating multilingual datasets and synthetic data generation]",
    "dataAnnotationHeading": "Data Annotation & Labeling",
    "dataAnnotationDesc": "[Insert sentence here about organizing and tagging data for AI readiness]",
    "dataValidationHeading": "Data Evaluation & Validation",
    "dataValidationDesc": "[Insert sentence here about measuring datasets to reduce bias and improve accuracy]",
    "modelTrainingHeading": "Model Training & Fine-Tuning",
    "modelTrainingDesc": "[Insert sentence here about refining pre-trained models with custom datasets]",
    "benchmarkingHeading": "Benchmarking & Model Evaluation",
    "benchmarkingDesc": "[Insert sentence here about structured benchmarking and expert-driven evaluation]",
    "platformHeading": "AI Data Management Platform",
    "platformDesc": "[Insert sentence here about integrated end-to-end data pipeline system]"
  },
  "services": {
    "dataCollection": {
      "heroHeading": "Data Collection & Enhancement",
      "heroSubheading": "[Insert sentence here about data collection services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about curating and sourcing raw multilingual data including text, audio, image across 120+ languages and regional dialects, plus synthetic data generation]"
    },
    "dataAnnotation": {
      "heroHeading": "Data Annotation & Labeling",
      "heroSubheading": "[Insert sentence here about annotation services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about organizing and tagging data for AI readiness using human annotators and AI-assisted tools with multi-pass review]"
    },
    "dataValidation": {
      "heroHeading": "Data Evaluation & Validation",
      "heroSubheading": "[Insert sentence here about validation services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about measuring and validating datasets to reduce bias, improve accuracy, and ensure enterprise-grade quality]"
    },
    "modelTraining": {
      "heroHeading": "Model Training & Fine-Tuning",
      "heroSubheading": "[Insert sentence here about model training services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about refining pre-trained LLMs with custom-curated multilingual and domain-specific datasets]"
    },
    "benchmarking": {
      "heroHeading": "Benchmarking & Model Evaluation",
      "heroSubheading": "[Insert sentence here about benchmarking services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about structured benchmarking datasets and expert-driven model evaluation across languages and domains]"
    },
    "platform": {
      "heroHeading": "AI Data Management Platform",
      "heroSubheading": "[Insert sentence here about platform services]",
      "overviewHeading": "Overview",
      "overviewContent": "[Insert content here about integrated end-to-end pipeline from collection to annotation to evaluation to fine-tuning]"
    }
  },
  "higherEd": {
    "heroHeading": "Higher Education Consulting",
    "heroSubheading": "We help universities maintain academic integrity in the AI era. Build policies that work without starting an arms race around detection.",
    "problemHeading": "The Problem",
    "problemPara1": "Graduate programs face declining trust in student work. Faculty cannot tell which submissions involve AI authorship. Detection tools generate false accusations. Administrators worry about accreditation standards while students demand access to AI tools.",
    "problemPara2": "Traditional honor codes assume students write everything themselves. That model breaks when AI can draft entire papers. Institutions need frameworks that acknowledge AI use without abandoning integrity standards.",
    "approachHeading": "Our Approach",
    "approachPara1": "We partner with universities to build academic integrity frameworks for AI environments. Faculty learn to assess student work when AI tools are involved. Institutions maintain standards while adopting AI responsibly.",
    "approachPara2": "Our consulting engagements combine policy development, faculty training, and implementation support. We start by understanding your institutional context and accreditation requirements. Then we design frameworks that fit your governance structure.",
    "offeringsHeading": "What We Offer",
    "policyDevHeading": "Policy Development",
    "policyDevText": "We draft AI use policies tailored to your program requirements. Policies specify when AI tools are permitted, what students must disclose, and how faculty verify learning outcomes.",
    "facultyTrainingHeading": "Faculty Training",
    "facultyTrainingText": "We train faculty to assess student work in AI environments. Training covers AI detection limitations, process-based assessment methods, and how to update assignment design.",
    "implementationHeading": "Implementation Support",
    "implementationText": "We help you roll out new policies across departments. Support includes communication plans, pilot programs, and feedback loops to refine your approach.",
    "accreditationHeading": "Accreditation Compliance",
    "accreditationText": "We ensure your AI policies meet accreditation standards. We document how your integrity frameworks maintain academic rigor and verify student learning.",
    "whyMattersHeading": "Why This Matters",
    "whyMattersPara1": "Institutions maintain accreditation while adapting to AI realities. Faculty gain confidence assessing student work. Students understand expectations clearly. Your policies reduce conflict instead of increasing surveillance.",
    "whyMattersPara2": "Detection-only approaches fail and damage trust. Our frameworks acknowledge AI use while preserving what matters: verifying that students learn the material."
  },
  "dataInfra": {
    "heroHeading": "Multilingual AI Training Data",
    "heroSubheading": "Verified training data across 120+ languages. Build AI systems that work fairly across cultures.",
    "problemHeading": "The Challenge",
    "problemPara1": "AI models trained on biased data produce biased results. Enterprise teams lack visibility into training data quality. Models fail when deployed across languages and cultures.",
    "problemPara2": "Standard datasets miss cultural context and regional variations. Teams cannot verify data sources or detect embedded bias before deployment.",
    "approachHeading": "Our Solution",
    "approachPara1": "We audit AI training datasets across 120+ languages. Native speakers verify cultural accuracy and flag bias. You deploy models with confidence across global markets.",
    "approachPara2": "Our verification covers translation quality, cultural appropriateness, and regional variations. We document data provenance and provide bias reports before you train models.",
    "offeringsHeading": "What We Provide",
    "dataAuditHeading": "Dataset Audit",
    "dataAuditText": "We review your training data for bias, quality issues, and cultural gaps. Reports identify problems by language and region.",
    "nativeVerificationHeading": "Native Speaker Verification",
    "nativeVerificationText": "Native speakers verify translations and cultural context. We catch issues automated tools miss.",
    "provenanceHeading": "Data Provenance Tracking",
    "provenanceText": "We document data sources and verify licensing. You know where your data comes from and how it can be used.",
    "biasReportHeading": "Bias Detection Reports",
    "biasReportText": "We surface embedded stereotypes and cultural bias. You address issues before deployment."
  },
  "evaluation": {
    "heroHeading": "Trustworthy AI Evaluation & Compliance",
    "heroSubheading": "Independent evaluation of AI model performance and compliance. Deploy with confidence and meet governance standards.",
    "problemHeading": "The Challenge",
    "problemPara1": "Regulatory frameworks require independent AI evaluation. Internal testing misses blind spots. Stakeholders demand proof of model safety and fairness.",
    "problemPara2": "Teams lack expertise to evaluate models against evolving standards. Compliance requirements vary by jurisdiction and industry.",
    "approachHeading": "Our Solution",
    "approachPara1": "We provide independent AI model evaluation against regulatory frameworks. Tests cover performance, fairness, safety, and compliance. You get third-party verification stakeholders trust.",
    "approachPara2": "Our evaluations align with EU AI Act, NIST guidelines, and industry standards. We test models in production conditions and provide detailed compliance reports.",
    "offeringsHeading": "What We Provide",
    "performanceHeading": "Performance Testing",
    "performanceText": "We test model accuracy, reliability, and edge cases. Reports show where models fail and why.",
    "fairnessHeading": "Fairness Evaluation",
    "fairnessText": "We measure bias across demographic groups and use cases. You identify and fix fairness issues before deployment.",
    "complianceHeading": "Regulatory Compliance",
    "complianceText": "We evaluate models against EU AI Act, NIST, and sector-specific regulations. Reports document compliance for auditors.",
    "safetyHeading": "Safety Assessment",
    "safetyText": "We test for harmful outputs, security vulnerabilities, and failure modes. You deploy safe models with documented risk mitigation."
  },
  "governance": {
    "heroHeading": "AI Governance Frameworks",
    "heroSubheading": "Policy frameworks for responsible AI adoption. Manage AI risk while enabling innovation.",
    "problemHeading": "The Challenge",
    "problemPara1": "Organizations adopt AI without governance structures. Teams cannot assess risk or ensure responsible use. Leadership lacks frameworks to manage AI deployment.",
    "problemPara2": "Off-the-shelf policies do not fit organizational contexts. Governance needs vary by industry, region, and risk tolerance.",
    "approachHeading": "Our Solution",
    "approachPara1": "We design AI governance frameworks tailored to your organization. Policies cover risk assessment, approval workflows, and accountability structures. You manage AI responsibly while enabling teams to innovate.",
    "approachPara2": "Our frameworks align with your existing compliance programs and risk management practices. We provide implementation support to ensure policies work in practice.",
    "offeringsHeading": "What We Provide",
    "policyDesignHeading": "Policy Framework Design",
    "policyDesignText": "We create AI governance policies that fit your organization. Frameworks cover approval, monitoring, and accountability.",
    "riskHeading": "Risk Assessment Tools",
    "riskText": "We build risk assessment frameworks for AI projects. Teams evaluate risk before deployment using clear criteria.",
    "workflowHeading": "Approval Workflows",
    "workflowText": "We design approval processes for AI deployments. Stakeholders review projects at appropriate risk levels.",
    "trainingHeading": "Governance Training",
    "trainingText": "We train teams on AI governance policies and tools. Staff understand their responsibilities and how to comply."
  },
  "higherEdSpokes": {
    "gradStudentIntegrity": {
      "heroHeading": "Graduate Student Integrity in AI Environments",
      "heroSubheading": "Help graduate students maintain integrity while using AI tools responsibly.",
      "contentPara": "Graduate students face pressure to use AI tools while meeting integrity standards. We train students on responsible AI use, help them document their work processes, and teach faculty to assess learning outcomes when AI tools are involved. Students learn to use AI as a research aid without compromising their intellectual development."
    },
    "authorizedLLMs": {
      "heroHeading": "Authorized Departmental LLMs",
      "heroSubheading": "Deploy secure, department-approved AI models that protect student data and meet compliance standards.",
      "contentPara": "Departments need secure AI tools that comply with FERPA and GDPR requirements. We help you deploy approved language models within your institutional boundaries. Students access AI tools without exposing sensitive data to third parties. Your institution maintains control over AI use while protecting privacy."
    },
    "facultyLiteracy": {
      "heroHeading": "Faculty AI Literacy Programs",
      "heroSubheading": "Train faculty to assess student work effectively in AI environments.",
      "contentPara": "Faculty need skills to evaluate student work when AI tools are involved. We provide training on AI detection limitations, process-based assessment methods, and assignment design updates. Faculty gain confidence assessing work and helping students use AI responsibly. Training aligns with your institutional policies and accreditation requirements."
    },
    "trustCharter": {
      "heroHeading": "Campus Trust Charter",
      "heroSubheading": "Build campus-wide integrity frameworks that work across departments.",
      "contentPara": "Institutions need consistent integrity standards across programs. We help you develop campus-wide trust charters that align with accreditation requirements. Provosts gain frameworks that work across departments. Your charter provides clear expectations for students and faculty while meeting institutional standards."
    },
    "trustCurrency": {
      "heroHeading": "Trust as Institutional Currency",
      "heroSubheading": "Position academic integrity as a competitive advantage for enrollment and funding.",
      "contentPara": "Trust becomes a recruitment and fundraising asset. We help leadership communicate integrity frameworks to prospective students and donors. Your institution demonstrates commitment to academic standards while adopting AI responsibly. Trust credentials differentiate your programs in competitive markets."
    },
    "ethicsCurriculum": {
      "heroHeading": "AI Ethics Curriculum Development",
      "heroSubheading": "Integrate AI ethics into graduate programs with critical review modules.",
      "contentPara": "Graduate programs need AI ethics content that fits their disciplines. We design curriculum modules on responsible AI use, critical evaluation of AI outputs, and ethical considerations. Faculty integrate ethics into existing courses or build standalone modules. Students develop critical thinking skills about AI tools."
    },
    "researchTools": {
      "heroHeading": "Research Integrity Tools",
      "heroSubheading": "Ethical tooling for research transparency and reproducibility.",
      "contentPara": "Researchers need tools to maintain integrity in data analysis and reporting. We provide research integrity resources including p-value calculators and bias detection tools. Universities demonstrate commitment to transparent research practices. Interactive tools help researchers identify common statistical errors before publication."
    }
  },
  "contact": {
    "heroHeading": "Contact Us",
    "heroSubheading": "Tell us about your needs. We'll respond within 24 hours.",
    "formHeading": "Send a Message",
    "nameLabel": "Your Name",
    "emailLabel": "Email Address",
    "messageLabel": "Message",
    "submitButton": "Send Message",
    "placeholder": "Contact form coming soon. Email us at contact@geoverity.com"
  },
  "footer": {
    "copyright": "¬© 2026 GeoVerity. All rights reserved."
  }
}
