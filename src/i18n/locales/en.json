{
  "common": {
    "skipToMain": "Skip to main content",
    "menu": "Menu",
    "closeMenu": "Close menu",
    "navigationOpened": "Navigation menu opened",
    "navigationClosed": "Navigation menu closed"
  },
  "nav": {
    "home": "Home",
    "services": "Services",
    "insights": "Insights",
    "contact": "Contact"
  },
  "languageSwitcher": {
    "label": "Language",
    "english": "English",
    "spanish": "Español"
  },
  "homepage": {
    "heroHeading": "Protecting Academic Integrity in the AI Era",
    "heroSubheading": "We help universities maintain trust in student work and research. Build AI policies that work without starting an arms race.",
    "heroCta": "Explore Our Services",
    "missionHeading": "Our Mission",
    "missionText": "We partner with universities to build academic integrity frameworks. Faculty learn to assess student work in AI environments. Institutions maintain standards while adopting AI responsibly."
  },
  "insightsHub": {
    "heroHeading": "Insights",
    "heroSubheading": "Exploring graduate education, epistemic responsibility, and AI use in academia.",
    "noPosts": "No posts available yet. Check back soon.",
    "categories": "Categories",
    "allPosts": "All Posts"
  },
  "insightsCategories": {
    "academicIntegrity": {
      "name": "Academic Integrity",
      "description": "Graduate education, authorized AI tools, and building trust frameworks for student work.",
      "heroHeading": "Academic Integrity",
      "heroSubheading": "Exploring how universities maintain trust in student work while adopting AI tools responsibly."
    },
    "aiGovernance": {
      "name": "AI Governance",
      "description": "Policy frameworks, disclosure requirements, and institutional governance for AI adoption.",
      "heroHeading": "AI Governance",
      "heroSubheading": "Building policy frameworks that manage AI risk while enabling innovation."
    },
    "multilingualData": {
      "name": "Multilingual Data",
      "description": "Dataset bias, language diversity, and ethical considerations in AI training data.",
      "heroHeading": "Multilingual Data",
      "heroSubheading": "Addressing bias and quality in AI training data across languages and cultures."
    },
    "trustEvaluation": {
      "name": "Trust and Evaluation",
      "description": "Model evaluation, bias audits, fairness testing, and trustworthy AI metrics.",
      "heroHeading": "Trust and Evaluation",
      "heroSubheading": "Independent evaluation of AI model performance, fairness, and compliance."
    },
    "researchIntegrity": {
      "name": "Research Integrity",
      "description": "Research transparency, p-value interpretation, reproducibility, and statistical rigor.",
      "heroHeading": "Research Integrity",
      "heroSubheading": "Tools and practices for maintaining transparency and reproducibility in research."
    }
  },
  "servicesHub": {
    "heroHeading": "Our Services",
    "heroSubheading": "We help organizations build trust in AI systems and protect academic integrity. Choose the service that fits your needs.",
    "higherEdHeading": "Higher Education Consulting",
    "higherEdDesc": "Universities maintain academic integrity in AI environments. We train faculty, build policies, and provide implementation support. Your institution adapts to AI while meeting accreditation standards.",
    "dataHeading": "Multilingual AI Training Data",
    "dataDesc": "Verified training data across 120+ languages. We audit datasets to surface bias before deployment. You build AI systems that work fairly across cultures.",
    "evaluationHeading": "Trustworthy AI Evaluation & Compliance",
    "evaluationDesc": "Independent evaluation of AI model performance and compliance. We test models against regulatory requirements. You deploy with confidence and meet governance standards.",
    "governanceHeading": "AI Governance Frameworks",
    "governanceDesc": "Policy frameworks for responsible AI adoption. We design governance systems that fit your organization. You manage AI risk while enabling innovation."
  },
  "higherEd": {
    "heroHeading": "Higher Education Consulting",
    "heroSubheading": "We help universities maintain academic integrity in the AI era. Build policies that work without starting an arms race around detection.",
    "problemHeading": "The Problem",
    "problemPara1": "Graduate programs face declining trust in student work. Faculty cannot tell which submissions involve AI authorship. Detection tools generate false accusations. Administrators worry about accreditation standards while students demand access to AI tools.",
    "problemPara2": "Traditional honor codes assume students write everything themselves. That model breaks when AI can draft entire papers. Institutions need frameworks that acknowledge AI use without abandoning integrity standards.",
    "approachHeading": "Our Approach",
    "approachPara1": "We partner with universities to build academic integrity frameworks for AI environments. Faculty learn to assess student work when AI tools are involved. Institutions maintain standards while adopting AI responsibly.",
    "approachPara2": "Our consulting engagements combine policy development, faculty training, and implementation support. We start by understanding your institutional context and accreditation requirements. Then we design frameworks that fit your governance structure.",
    "offeringsHeading": "What We Offer",
    "policyDevHeading": "Policy Development",
    "policyDevText": "We draft AI use policies tailored to your program requirements. Policies specify when AI tools are permitted, what students must disclose, and how faculty verify learning outcomes.",
    "facultyTrainingHeading": "Faculty Training",
    "facultyTrainingText": "We train faculty to assess student work in AI environments. Training covers AI detection limitations, process-based assessment methods, and how to update assignment design.",
    "implementationHeading": "Implementation Support",
    "implementationText": "We help you roll out new policies across departments. Support includes communication plans, pilot programs, and feedback loops to refine your approach.",
    "accreditationHeading": "Accreditation Compliance",
    "accreditationText": "We ensure your AI policies meet accreditation standards. We document how your integrity frameworks maintain academic rigor and verify student learning.",
    "whyMattersHeading": "Why This Matters",
    "whyMattersPara1": "Institutions maintain accreditation while adapting to AI realities. Faculty gain confidence assessing student work. Students understand expectations clearly. Your policies reduce conflict instead of increasing surveillance.",
    "whyMattersPara2": "Detection-only approaches fail and damage trust. Our frameworks acknowledge AI use while preserving what matters: verifying that students learn the material."
  },
  "dataInfra": {
    "heroHeading": "Multilingual AI Training Data",
    "heroSubheading": "Verified training data across 120+ languages. Build AI systems that work fairly across cultures.",
    "problemHeading": "The Challenge",
    "problemPara1": "AI models trained on biased data produce biased results. Enterprise teams lack visibility into training data quality. Models fail when deployed across languages and cultures.",
    "problemPara2": "Standard datasets miss cultural context and regional variations. Teams cannot verify data sources or detect embedded bias before deployment.",
    "approachHeading": "Our Solution",
    "approachPara1": "We audit AI training datasets across 120+ languages. Native speakers verify cultural accuracy and flag bias. You deploy models with confidence across global markets.",
    "approachPara2": "Our verification covers translation quality, cultural appropriateness, and regional variations. We document data provenance and provide bias reports before you train models.",
    "offeringsHeading": "What We Provide",
    "dataAuditHeading": "Dataset Audit",
    "dataAuditText": "We review your training data for bias, quality issues, and cultural gaps. Reports identify problems by language and region.",
    "nativeVerificationHeading": "Native Speaker Verification",
    "nativeVerificationText": "Native speakers verify translations and cultural context. We catch issues automated tools miss.",
    "provenanceHeading": "Data Provenance Tracking",
    "provenanceText": "We document data sources and verify licensing. You know where your data comes from and how it can be used.",
    "biasReportHeading": "Bias Detection Reports",
    "biasReportText": "We surface embedded stereotypes and cultural bias. You address issues before deployment."
  },
  "evaluation": {
    "heroHeading": "Trustworthy AI Evaluation & Compliance",
    "heroSubheading": "Independent evaluation of AI model performance and compliance. Deploy with confidence and meet governance standards.",
    "problemHeading": "The Challenge",
    "problemPara1": "Regulatory frameworks require independent AI evaluation. Internal testing misses blind spots. Stakeholders demand proof of model safety and fairness.",
    "problemPara2": "Teams lack expertise to evaluate models against evolving standards. Compliance requirements vary by jurisdiction and industry.",
    "approachHeading": "Our Solution",
    "approachPara1": "We provide independent AI model evaluation against regulatory frameworks. Tests cover performance, fairness, safety, and compliance. You get third-party verification stakeholders trust.",
    "approachPara2": "Our evaluations align with EU AI Act, NIST guidelines, and industry standards. We test models in production conditions and provide detailed compliance reports.",
    "offeringsHeading": "What We Provide",
    "performanceHeading": "Performance Testing",
    "performanceText": "We test model accuracy, reliability, and edge cases. Reports show where models fail and why.",
    "fairnessHeading": "Fairness Evaluation",
    "fairnessText": "We measure bias across demographic groups and use cases. You identify and fix fairness issues before deployment.",
    "complianceHeading": "Regulatory Compliance",
    "complianceText": "We evaluate models against EU AI Act, NIST, and sector-specific regulations. Reports document compliance for auditors.",
    "safetyHeading": "Safety Assessment",
    "safetyText": "We test for harmful outputs, security vulnerabilities, and failure modes. You deploy safe models with documented risk mitigation."
  },
  "governance": {
    "heroHeading": "AI Governance Frameworks",
    "heroSubheading": "Policy frameworks for responsible AI adoption. Manage AI risk while enabling innovation.",
    "problemHeading": "The Challenge",
    "problemPara1": "Organizations adopt AI without governance structures. Teams cannot assess risk or ensure responsible use. Leadership lacks frameworks to manage AI deployment.",
    "problemPara2": "Off-the-shelf policies do not fit organizational contexts. Governance needs vary by industry, region, and risk tolerance.",
    "approachHeading": "Our Solution",
    "approachPara1": "We design AI governance frameworks tailored to your organization. Policies cover risk assessment, approval workflows, and accountability structures. You manage AI responsibly while enabling teams to innovate.",
    "approachPara2": "Our frameworks align with your existing compliance programs and risk management practices. We provide implementation support to ensure policies work in practice.",
    "offeringsHeading": "What We Provide",
    "policyDesignHeading": "Policy Framework Design",
    "policyDesignText": "We create AI governance policies that fit your organization. Frameworks cover approval, monitoring, and accountability.",
    "riskHeading": "Risk Assessment Tools",
    "riskText": "We build risk assessment frameworks for AI projects. Teams evaluate risk before deployment using clear criteria.",
    "workflowHeading": "Approval Workflows",
    "workflowText": "We design approval processes for AI deployments. Stakeholders review projects at appropriate risk levels.",
    "trainingHeading": "Governance Training",
    "trainingText": "We train teams on AI governance policies and tools. Staff understand their responsibilities and how to comply."
  },
  "higherEdSpokes": {
    "gradStudentIntegrity": {
      "heroHeading": "Graduate Student Integrity in AI Environments",
      "heroSubheading": "Help graduate students maintain integrity while using AI tools responsibly.",
      "contentPara": "Graduate students face pressure to use AI tools while meeting integrity standards. We train students on responsible AI use, help them document their work processes, and teach faculty to assess learning outcomes when AI tools are involved. Students learn to use AI as a research aid without compromising their intellectual development."
    },
    "authorizedLLMs": {
      "heroHeading": "Authorized Departmental LLMs",
      "heroSubheading": "Deploy secure, department-approved AI models that protect student data and meet compliance standards.",
      "contentPara": "Departments need secure AI tools that comply with FERPA and GDPR requirements. We help you deploy approved language models within your institutional boundaries. Students access AI tools without exposing sensitive data to third parties. Your institution maintains control over AI use while protecting privacy."
    },
    "facultyLiteracy": {
      "heroHeading": "Faculty AI Literacy Programs",
      "heroSubheading": "Train faculty to assess student work effectively in AI environments.",
      "contentPara": "Faculty need skills to evaluate student work when AI tools are involved. We provide training on AI detection limitations, process-based assessment methods, and assignment design updates. Faculty gain confidence assessing work and helping students use AI responsibly. Training aligns with your institutional policies and accreditation requirements."
    },
    "trustCharter": {
      "heroHeading": "Campus Trust Charter",
      "heroSubheading": "Build campus-wide integrity frameworks that work across departments.",
      "contentPara": "Institutions need consistent integrity standards across programs. We help you develop campus-wide trust charters that align with accreditation requirements. Provosts gain frameworks that work across departments. Your charter provides clear expectations for students and faculty while meeting institutional standards."
    },
    "trustCurrency": {
      "heroHeading": "Trust as Institutional Currency",
      "heroSubheading": "Position academic integrity as a competitive advantage for enrollment and funding.",
      "contentPara": "Trust becomes a recruitment and fundraising asset. We help leadership communicate integrity frameworks to prospective students and donors. Your institution demonstrates commitment to academic standards while adopting AI responsibly. Trust credentials differentiate your programs in competitive markets."
    },
    "ethicsCurriculum": {
      "heroHeading": "AI Ethics Curriculum Development",
      "heroSubheading": "Integrate AI ethics into graduate programs with critical review modules.",
      "contentPara": "Graduate programs need AI ethics content that fits their disciplines. We design curriculum modules on responsible AI use, critical evaluation of AI outputs, and ethical considerations. Faculty integrate ethics into existing courses or build standalone modules. Students develop critical thinking skills about AI tools."
    },
    "researchTools": {
      "heroHeading": "Research Integrity Tools",
      "heroSubheading": "Ethical tooling for research transparency and reproducibility.",
      "contentPara": "Researchers need tools to maintain integrity in data analysis and reporting. We provide research integrity resources including p-value calculators and bias detection tools. Universities demonstrate commitment to transparent research practices. Interactive tools help researchers identify common statistical errors before publication."
    }
  },
  "contact": {
    "heroHeading": "Contact Us",
    "heroSubheading": "Tell us about your needs. We'll respond within 24 hours.",
    "formHeading": "Send a Message",
    "nameLabel": "Your Name",
    "emailLabel": "Email Address",
    "messageLabel": "Message",
    "submitButton": "Send Message",
    "placeholder": "Contact form coming soon. Email us at contact@geoverity.com"
  },
  "footer": {
    "copyright": "© 2026 GeoVerity. All rights reserved."
  }
}
