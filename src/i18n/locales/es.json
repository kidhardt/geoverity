{
  "common": {
    "skipToMain": "Saltar al contenido principal",
    "menu": "Menú",
    "closeMenu": "Cerrar menú",
    "navigationOpened": "Menú de navegación abierto",
    "navigationClosed": "Menú de navegación cerrado"
  },
  "nav": {
    "home": "Inicio",
    "services": "Servicios",
    "insights": "Perspectivas",
    "contact": "Contacto"
  },
  "languageSwitcher": {
    "label": "Idioma",
    "english": "English",
    "spanish": "Español"
  },
  "homepage": {
    "heroHeading": "Protegiendo la Integridad Académica en la Era de IA",
    "heroSubheading": "Ayudamos a las universidades a mantener la confianza en el trabajo estudiantil y la investigación. Construye políticas de IA que funcionan sin iniciar una carrera armamentista.",
    "heroCta": "Explore Nuestros Servicios",
    "missionHeading": "Nuestra Misión",
    "missionText": "Nos asociamos con universidades para construir marcos de integridad académica. Los profesores aprenden a evaluar el trabajo estudiantil en entornos de IA. Las instituciones mantienen estándares mientras adoptan IA de manera responsable."
  },
  "insightsHub": {
    "heroHeading": "Perspectivas",
    "heroSubheading": "Explorando educación de posgrado, responsabilidad epistémica y uso de IA en el ámbito académico.",
    "noPosts": "Aún no hay publicaciones disponibles. Vuelve pronto.",
    "categories": "Categorías",
    "allPosts": "Todas las Publicaciones"
  },
  "servicesHub": {
    "heroHeading": "Nuestros Servicios",
    "heroSubheading": "Ayudamos a organizaciones a construir confianza en sistemas de IA y proteger la integridad académica. Elige el servicio que se ajusta a tus necesidades.",
    "higherEdHeading": "Consultoría para Educación Superior",
    "higherEdDesc": "Las universidades mantienen la integridad académica en entornos con IA. Capacitamos profesores, construimos políticas y brindamos apoyo en implementación. Tu institución se adapta a la IA mientras cumple con los estándares de acreditación.",
    "dataHeading": "Datos de Entrenamiento de IA Multilingües",
    "dataDesc": "Datos de entrenamiento verificados en más de 120 idiomas. Auditamos conjuntos de datos para detectar sesgos antes del despliegue. Construyes sistemas de IA que funcionan equitativamente en todas las culturas.",
    "evaluationHeading": "Evaluación de IA Confiable y Cumplimiento",
    "evaluationDesc": "Evaluación independiente del rendimiento y cumplimiento de modelos de IA. Probamos modelos contra requisitos regulatorios. Despliegas con confianza y cumples con los estándares de gobernanza.",
    "governanceHeading": "Marcos de Gobernanza de IA",
    "governanceDesc": "Marcos de políticas para la adopción responsable de IA. Diseñamos sistemas de gobernanza que se ajustan a tu organización. Gestionas el riesgo de IA mientras permites la innovación."
  },
  "higherEd": {
    "heroHeading": "Consultoría para Educación Superior",
    "heroSubheading": "Ayudamos a las universidades a mantener la integridad académica en la era de la IA. Construimos políticas que funcionan sin iniciar una carrera armamentista de detección.",
    "problemHeading": "El Problema",
    "problemPara1": "Los programas de posgrado enfrentan una pérdida de confianza en el trabajo estudiantil. Los profesores no pueden determinar qué trabajos involucran autoría con IA. Las herramientas de detección generan acusaciones falsas. Los administradores se preocupan por los estándares de acreditación mientras los estudiantes demandan acceso a herramientas de IA.",
    "problemPara2": "Los códigos de honor tradicionales asumen que los estudiantes escriben todo ellos mismos. Ese modelo falla cuando la IA puede redactar documentos completos. Las instituciones necesitan marcos que reconozcan el uso de IA sin abandonar los estándares de integridad.",
    "approachHeading": "Nuestro Enfoque",
    "approachPara1": "Trabajamos con universidades para construir marcos de integridad académica para entornos con IA. Los profesores aprenden a evaluar el trabajo estudiantil cuando se involucran herramientas de IA. Las instituciones mantienen estándares mientras adoptan la IA de manera responsable.",
    "approachPara2": "Nuestras consultorías combinan desarrollo de políticas, capacitación docente y apoyo en implementación. Comenzamos entendiendo su contexto institucional y requisitos de acreditación. Luego diseñamos marcos que se ajustan a su estructura de gobernanza.",
    "offeringsHeading": "Qué Ofrecemos",
    "policyDevHeading": "Desarrollo de Políticas",
    "policyDevText": "Redactamos políticas de uso de IA adaptadas a los requisitos de su programa. Las políticas especifican cuándo se permiten herramientas de IA, qué deben revelar los estudiantes y cómo los profesores verifican los resultados de aprendizaje.",
    "facultyTrainingHeading": "Capacitación Docente",
    "facultyTrainingText": "Capacitamos a los profesores para evaluar el trabajo estudiantil en entornos con IA. La capacitación cubre las limitaciones de la detección de IA, métodos de evaluación basados en procesos y cómo actualizar el diseño de tareas.",
    "implementationHeading": "Apoyo en Implementación",
    "implementationText": "Le ayudamos a implementar nuevas políticas en todos los departamentos. El apoyo incluye planes de comunicación, programas piloto y ciclos de retroalimentación para refinar su enfoque.",
    "accreditationHeading": "Cumplimiento de Acreditación",
    "accreditationText": "Aseguramos que sus políticas de IA cumplan con los estándares de acreditación. Documentamos cómo sus marcos de integridad mantienen el rigor académico y verifican el aprendizaje estudiantil.",
    "whyMattersHeading": "Por Qué Esto Importa",
    "whyMattersPara1": "Las instituciones mantienen la acreditación mientras se adaptan a las realidades de la IA. Los profesores ganan confianza al evaluar el trabajo estudiantil. Los estudiantes entienden las expectativas claramente. Sus políticas reducen el conflicto en lugar de aumentar la vigilancia.",
    "whyMattersPara2": "Los enfoques basados solo en detección fallan y dañan la confianza. Nuestros marcos reconocen el uso de IA mientras preservan lo que importa: verificar que los estudiantes aprendan el material."
  },
  "dataInfra": {
    "heroHeading": "Datos de Entrenamiento de IA Multilingües",
    "heroSubheading": "Datos de entrenamiento verificados en más de 120 idiomas. Construye sistemas de IA que funcionan equitativamente en todas las culturas.",
    "problemHeading": "El Desafío",
    "problemPara1": "Los modelos de IA entrenados con datos sesgados producen resultados sesgados. Los equipos empresariales carecen de visibilidad sobre la calidad de los datos de entrenamiento. Los modelos fallan cuando se despliegan en diferentes idiomas y culturas.",
    "problemPara2": "Los conjuntos de datos estándar pierden el contexto cultural y las variaciones regionales. Los equipos no pueden verificar las fuentes de datos ni detectar sesgos incorporados antes del despliegue.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Auditamos conjuntos de datos de entrenamiento de IA en más de 120 idiomas. Los hablantes nativos verifican la precisión cultural y marcan sesgos. Despliegas modelos con confianza en mercados globales.",
    "approachPara2": "Nuestra verificación cubre la calidad de la traducción, la idoneidad cultural y las variaciones regionales. Documentamos la procedencia de los datos y proporcionamos informes de sesgos antes de que entrenes modelos.",
    "offeringsHeading": "Qué Proporcionamos",
    "dataAuditHeading": "Auditoría de Conjuntos de Datos",
    "dataAuditText": "Revisamos tus datos de entrenamiento en busca de sesgos, problemas de calidad y brechas culturales. Los informes identifican problemas por idioma y región.",
    "nativeVerificationHeading": "Verificación por Hablantes Nativos",
    "nativeVerificationText": "Los hablantes nativos verifican las traducciones y el contexto cultural. Detectamos problemas que las herramientas automatizadas pierden.",
    "provenanceHeading": "Seguimiento de Procedencia de Datos",
    "provenanceText": "Documentamos las fuentes de datos y verificamos las licencias. Sabes de dónde vienen tus datos y cómo se pueden usar.",
    "biasReportHeading": "Informes de Detección de Sesgos",
    "biasReportText": "Detectamos estereotipos y sesgos culturales incorporados. Abordas los problemas antes del despliegue."
  },
  "evaluation": {
    "heroHeading": "Evaluación de IA Confiable y Cumplimiento",
    "heroSubheading": "Evaluación independiente del rendimiento y cumplimiento de modelos de IA. Despliega con confianza y cumple con los estándares de gobernanza.",
    "problemHeading": "El Desafío",
    "problemPara1": "Los marcos regulatorios requieren evaluación independiente de IA. Las pruebas internas pierden puntos ciegos. Las partes interesadas demandan prueba de seguridad y equidad del modelo.",
    "problemPara2": "Los equipos carecen de experiencia para evaluar modelos contra estándares en evolución. Los requisitos de cumplimiento varían según la jurisdicción y la industria.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Proporcionamos evaluación independiente de modelos de IA contra marcos regulatorios. Las pruebas cubren rendimiento, equidad, seguridad y cumplimiento. Obtienes verificación de terceros en la que las partes interesadas confían.",
    "approachPara2": "Nuestras evaluaciones se alinean con la Ley de IA de la UE, las pautas de NIST y los estándares de la industria. Probamos modelos en condiciones de producción y proporcionamos informes de cumplimiento detallados.",
    "offeringsHeading": "Qué Proporcionamos",
    "performanceHeading": "Pruebas de Rendimiento",
    "performanceText": "Probamos la precisión, confiabilidad y casos extremos del modelo. Los informes muestran dónde fallan los modelos y por qué.",
    "fairnessHeading": "Evaluación de Equidad",
    "fairnessText": "Medimos el sesgo en grupos demográficos y casos de uso. Identificas y corriges problemas de equidad antes del despliegue.",
    "complianceHeading": "Cumplimiento Regulatorio",
    "complianceText": "Evaluamos modelos contra la Ley de IA de la UE, NIST y regulaciones específicas del sector. Los informes documentan el cumplimiento para los auditores.",
    "safetyHeading": "Evaluación de Seguridad",
    "safetyText": "Probamos resultados dañinos, vulnerabilidades de seguridad y modos de falla. Despliegas modelos seguros con mitigación de riesgos documentada."
  },
  "governance": {
    "heroHeading": "Marcos de Gobernanza de IA",
    "heroSubheading": "Marcos de políticas para la adopción responsable de IA. Gestiona el riesgo de IA mientras permites la innovación.",
    "problemHeading": "El Desafío",
    "problemPara1": "Las organizaciones adoptan IA sin estructuras de gobernanza. Los equipos no pueden evaluar el riesgo ni garantizar un uso responsable. El liderazgo carece de marcos para gestionar el despliegue de IA.",
    "problemPara2": "Las políticas estándar no se ajustan a los contextos organizacionales. Las necesidades de gobernanza varían según la industria, la región y la tolerancia al riesgo.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Diseñamos marcos de gobernanza de IA adaptados a tu organización. Las políticas cubren evaluación de riesgos, flujos de aprobación y estructuras de responsabilidad. Gestionas la IA de manera responsable mientras permites que los equipos innoven.",
    "approachPara2": "Nuestros marcos se alinean con tus programas de cumplimiento existentes y prácticas de gestión de riesgos. Proporcionamos apoyo en la implementación para garantizar que las políticas funcionen en la práctica.",
    "offeringsHeading": "Qué Proporcionamos",
    "policyDesignHeading": "Diseño de Marco de Políticas",
    "policyDesignText": "Creamos políticas de gobernanza de IA que se ajustan a tu organización. Los marcos cubren aprobación, monitoreo y responsabilidad.",
    "riskHeading": "Herramientas de Evaluación de Riesgos",
    "riskText": "Construimos marcos de evaluación de riesgos para proyectos de IA. Los equipos evalúan el riesgo antes del despliegue usando criterios claros.",
    "workflowHeading": "Flujos de Aprobación",
    "workflowText": "Diseñamos procesos de aprobación para despliegues de IA. Las partes interesadas revisan proyectos en niveles de riesgo apropiados.",
    "trainingHeading": "Capacitación en Gobernanza",
    "trainingText": "Capacitamos equipos en políticas y herramientas de gobernanza de IA. El personal entiende sus responsabilidades y cómo cumplir."
  },
  "contact": {
    "heroHeading": "Contáctanos",
    "heroSubheading": "Cuéntanos sobre tus necesidades. Responderemos en 24 horas.",
    "formHeading": "Enviar un Mensaje",
    "nameLabel": "Tu Nombre",
    "emailLabel": "Correo Electrónico",
    "messageLabel": "Mensaje",
    "submitButton": "Enviar Mensaje",
    "placeholder": "Formulario de contacto próximamente. Escríbenos a contact@geoverity.com"
  },
  "footer": {
    "copyright": "© 2026 GeoVerity. Todos los derechos reservados."
  }
}
