{
  "common": {
    "skipToMain": "Saltar al contenido principal",
    "menu": "Menú",
    "closeMenu": "Cerrar menú",
    "navigationOpened": "Menú de navegación abierto",
    "navigationClosed": "Menú de navegación cerrado"
  },
  "nav": {
    "home": "Inicio",
    "services": "Servicios",
    "insights": "Perspectivas",
    "contact": "Contacto"
  },
  "languageSwitcher": {
    "label": "Idioma",
    "english": "English",
    "spanish": "Español"
  },
  "homepage": {
    "heroHeading": "Protegiendo la Integridad Académica en la Era de IA",
    "heroSubheading": "Ayudamos a las universidades a mantener la confianza en el trabajo estudiantil y la investigación. Construye políticas de IA que funcionan sin iniciar una carrera armamentista.",
    "heroCta": "Explore Nuestros Servicios",
    "missionHeading": "Nuestra Misión",
    "missionText": "Nos asociamos con universidades para construir marcos de integridad académica. Los profesores aprenden a evaluar el trabajo estudiantil en entornos de IA. Las instituciones mantienen estándares mientras adoptan IA de manera responsable."
  },
  "insightsHub": {
    "heroHeading": "Perspectivas",
    "heroSubheading": "Explorando educación de posgrado, responsabilidad epistémica y uso de IA en el ámbito académico.",
    "noPosts": "Aún no hay publicaciones disponibles. Vuelve pronto.",
    "categories": "Categorías",
    "allPosts": "Todas las Publicaciones"
  },
  "insightsCategories": {
    "academicIntegrity": {
      "name": "Integridad Académica",
      "description": "Educación de posgrado, herramientas de IA autorizadas y construcción de marcos de confianza para el trabajo estudiantil.",
      "heroHeading": "Integridad Académica",
      "heroSubheading": "Explorando cómo las universidades mantienen la confianza en el trabajo estudiantil mientras adoptan herramientas de IA de manera responsable."
    },
    "aiGovernance": {
      "name": "Gobernanza de IA",
      "description": "Marcos de políticas, requisitos de divulgación y gobernanza institucional para la adopción de IA.",
      "heroHeading": "Gobernanza de IA",
      "heroSubheading": "Construyendo marcos de políticas que gestionan el riesgo de IA mientras permiten la innovación."
    },
    "multilingualData": {
      "name": "Datos Multilingües",
      "description": "Sesgo en conjuntos de datos, diversidad lingüística y consideraciones éticas en datos de entrenamiento de IA.",
      "heroHeading": "Datos Multilingües",
      "heroSubheading": "Abordando el sesgo y la calidad en los datos de entrenamiento de IA en diferentes idiomas y culturas."
    },
    "trustEvaluation": {
      "name": "Confianza y Evaluación",
      "description": "Evaluación de modelos, auditorías de sesgo, pruebas de equidad y métricas de IA confiable.",
      "heroHeading": "Confianza y Evaluación",
      "heroSubheading": "Evaluación independiente del rendimiento, equidad y cumplimiento de modelos de IA."
    },
    "researchIntegrity": {
      "name": "Integridad en Investigación",
      "description": "Transparencia en investigación, interpretación de valores p, reproducibilidad y rigor estadístico.",
      "heroHeading": "Integridad en Investigación",
      "heroSubheading": "Herramientas y prácticas para mantener la transparencia y reproducibilidad en la investigación."
    }
  },
  "servicesHub": {
    "heroHeading": "Nuestros Servicios",
    "heroSubheading": "Ayudamos a organizaciones a construir confianza en sistemas de IA y proteger la integridad académica. Elige el servicio que se ajusta a tus necesidades.",
    "higherEdHeading": "Consultoría para Educación Superior",
    "higherEdDesc": "Las universidades mantienen la integridad académica en entornos con IA. Capacitamos profesores, construimos políticas y brindamos apoyo en implementación. Tu institución se adapta a la IA mientras cumple con los estándares de acreditación.",
    "dataHeading": "Datos de Entrenamiento de IA Multilingües",
    "dataDesc": "Datos de entrenamiento verificados en más de 120 idiomas. Auditamos conjuntos de datos para detectar sesgos antes del despliegue. Construyes sistemas de IA que funcionan equitativamente en todas las culturas.",
    "evaluationHeading": "Evaluación de IA Confiable y Cumplimiento",
    "evaluationDesc": "Evaluación independiente del rendimiento y cumplimiento de modelos de IA. Probamos modelos contra requisitos regulatorios. Despliegas con confianza y cumples con los estándares de gobernanza.",
    "governanceHeading": "Marcos de Gobernanza de IA",
    "governanceDesc": "Marcos de políticas para la adopción responsable de IA. Diseñamos sistemas de gobernanza que se ajustan a tu organización. Gestionas el riesgo de IA mientras permites la innovación."
  },
  "higherEd": {
    "heroHeading": "Consultoría para Educación Superior",
    "heroSubheading": "Ayudamos a las universidades a mantener la integridad académica en la era de la IA. Construimos políticas que funcionan sin iniciar una carrera armamentista de detección.",
    "problemHeading": "El Problema",
    "problemPara1": "Los programas de posgrado enfrentan una pérdida de confianza en el trabajo estudiantil. Los profesores no pueden determinar qué trabajos involucran autoría con IA. Las herramientas de detección generan acusaciones falsas. Los administradores se preocupan por los estándares de acreditación mientras los estudiantes demandan acceso a herramientas de IA.",
    "problemPara2": "Los códigos de honor tradicionales asumen que los estudiantes escriben todo ellos mismos. Ese modelo falla cuando la IA puede redactar documentos completos. Las instituciones necesitan marcos que reconozcan el uso de IA sin abandonar los estándares de integridad.",
    "approachHeading": "Nuestro Enfoque",
    "approachPara1": "Trabajamos con universidades para construir marcos de integridad académica para entornos con IA. Los profesores aprenden a evaluar el trabajo estudiantil cuando se involucran herramientas de IA. Las instituciones mantienen estándares mientras adoptan la IA de manera responsable.",
    "approachPara2": "Nuestras consultorías combinan desarrollo de políticas, capacitación docente y apoyo en implementación. Comenzamos entendiendo su contexto institucional y requisitos de acreditación. Luego diseñamos marcos que se ajustan a su estructura de gobernanza.",
    "offeringsHeading": "Qué Ofrecemos",
    "policyDevHeading": "Desarrollo de Políticas",
    "policyDevText": "Redactamos políticas de uso de IA adaptadas a los requisitos de su programa. Las políticas especifican cuándo se permiten herramientas de IA, qué deben revelar los estudiantes y cómo los profesores verifican los resultados de aprendizaje.",
    "facultyTrainingHeading": "Capacitación Docente",
    "facultyTrainingText": "Capacitamos a los profesores para evaluar el trabajo estudiantil en entornos con IA. La capacitación cubre las limitaciones de la detección de IA, métodos de evaluación basados en procesos y cómo actualizar el diseño de tareas.",
    "implementationHeading": "Apoyo en Implementación",
    "implementationText": "Le ayudamos a implementar nuevas políticas en todos los departamentos. El apoyo incluye planes de comunicación, programas piloto y ciclos de retroalimentación para refinar su enfoque.",
    "accreditationHeading": "Cumplimiento de Acreditación",
    "accreditationText": "Aseguramos que sus políticas de IA cumplan con los estándares de acreditación. Documentamos cómo sus marcos de integridad mantienen el rigor académico y verifican el aprendizaje estudiantil.",
    "whyMattersHeading": "Por Qué Esto Importa",
    "whyMattersPara1": "Las instituciones mantienen la acreditación mientras se adaptan a las realidades de la IA. Los profesores ganan confianza al evaluar el trabajo estudiantil. Los estudiantes entienden las expectativas claramente. Sus políticas reducen el conflicto en lugar de aumentar la vigilancia.",
    "whyMattersPara2": "Los enfoques basados solo en detección fallan y dañan la confianza. Nuestros marcos reconocen el uso de IA mientras preservan lo que importa: verificar que los estudiantes aprendan el material."
  },
  "dataInfra": {
    "heroHeading": "Datos de Entrenamiento de IA Multilingües",
    "heroSubheading": "Datos de entrenamiento verificados en más de 120 idiomas. Construye sistemas de IA que funcionan equitativamente en todas las culturas.",
    "problemHeading": "El Desafío",
    "problemPara1": "Los modelos de IA entrenados con datos sesgados producen resultados sesgados. Los equipos empresariales carecen de visibilidad sobre la calidad de los datos de entrenamiento. Los modelos fallan cuando se despliegan en diferentes idiomas y culturas.",
    "problemPara2": "Los conjuntos de datos estándar pierden el contexto cultural y las variaciones regionales. Los equipos no pueden verificar las fuentes de datos ni detectar sesgos incorporados antes del despliegue.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Auditamos conjuntos de datos de entrenamiento de IA en más de 120 idiomas. Los hablantes nativos verifican la precisión cultural y marcan sesgos. Despliegas modelos con confianza en mercados globales.",
    "approachPara2": "Nuestra verificación cubre la calidad de la traducción, la idoneidad cultural y las variaciones regionales. Documentamos la procedencia de los datos y proporcionamos informes de sesgos antes de que entrenes modelos.",
    "offeringsHeading": "Qué Proporcionamos",
    "dataAuditHeading": "Auditoría de Conjuntos de Datos",
    "dataAuditText": "Revisamos tus datos de entrenamiento en busca de sesgos, problemas de calidad y brechas culturales. Los informes identifican problemas por idioma y región.",
    "nativeVerificationHeading": "Verificación por Hablantes Nativos",
    "nativeVerificationText": "Los hablantes nativos verifican las traducciones y el contexto cultural. Detectamos problemas que las herramientas automatizadas pierden.",
    "provenanceHeading": "Seguimiento de Procedencia de Datos",
    "provenanceText": "Documentamos las fuentes de datos y verificamos las licencias. Sabes de dónde vienen tus datos y cómo se pueden usar.",
    "biasReportHeading": "Informes de Detección de Sesgos",
    "biasReportText": "Detectamos estereotipos y sesgos culturales incorporados. Abordas los problemas antes del despliegue."
  },
  "evaluation": {
    "heroHeading": "Evaluación de IA Confiable y Cumplimiento",
    "heroSubheading": "Evaluación independiente del rendimiento y cumplimiento de modelos de IA. Despliega con confianza y cumple con los estándares de gobernanza.",
    "problemHeading": "El Desafío",
    "problemPara1": "Los marcos regulatorios requieren evaluación independiente de IA. Las pruebas internas pierden puntos ciegos. Las partes interesadas demandan prueba de seguridad y equidad del modelo.",
    "problemPara2": "Los equipos carecen de experiencia para evaluar modelos contra estándares en evolución. Los requisitos de cumplimiento varían según la jurisdicción y la industria.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Proporcionamos evaluación independiente de modelos de IA contra marcos regulatorios. Las pruebas cubren rendimiento, equidad, seguridad y cumplimiento. Obtienes verificación de terceros en la que las partes interesadas confían.",
    "approachPara2": "Nuestras evaluaciones se alinean con la Ley de IA de la UE, las pautas de NIST y los estándares de la industria. Probamos modelos en condiciones de producción y proporcionamos informes de cumplimiento detallados.",
    "offeringsHeading": "Qué Proporcionamos",
    "performanceHeading": "Pruebas de Rendimiento",
    "performanceText": "Probamos la precisión, confiabilidad y casos extremos del modelo. Los informes muestran dónde fallan los modelos y por qué.",
    "fairnessHeading": "Evaluación de Equidad",
    "fairnessText": "Medimos el sesgo en grupos demográficos y casos de uso. Identificas y corriges problemas de equidad antes del despliegue.",
    "complianceHeading": "Cumplimiento Regulatorio",
    "complianceText": "Evaluamos modelos contra la Ley de IA de la UE, NIST y regulaciones específicas del sector. Los informes documentan el cumplimiento para los auditores.",
    "safetyHeading": "Evaluación de Seguridad",
    "safetyText": "Probamos resultados dañinos, vulnerabilidades de seguridad y modos de falla. Despliegas modelos seguros con mitigación de riesgos documentada."
  },
  "governance": {
    "heroHeading": "Marcos de Gobernanza de IA",
    "heroSubheading": "Marcos de políticas para la adopción responsable de IA. Gestiona el riesgo de IA mientras permites la innovación.",
    "problemHeading": "El Desafío",
    "problemPara1": "Las organizaciones adoptan IA sin estructuras de gobernanza. Los equipos no pueden evaluar el riesgo ni garantizar un uso responsable. El liderazgo carece de marcos para gestionar el despliegue de IA.",
    "problemPara2": "Las políticas estándar no se ajustan a los contextos organizacionales. Las necesidades de gobernanza varían según la industria, la región y la tolerancia al riesgo.",
    "approachHeading": "Nuestra Solución",
    "approachPara1": "Diseñamos marcos de gobernanza de IA adaptados a tu organización. Las políticas cubren evaluación de riesgos, flujos de aprobación y estructuras de responsabilidad. Gestionas la IA de manera responsable mientras permites que los equipos innoven.",
    "approachPara2": "Nuestros marcos se alinean con tus programas de cumplimiento existentes y prácticas de gestión de riesgos. Proporcionamos apoyo en la implementación para garantizar que las políticas funcionen en la práctica.",
    "offeringsHeading": "Qué Proporcionamos",
    "policyDesignHeading": "Diseño de Marco de Políticas",
    "policyDesignText": "Creamos políticas de gobernanza de IA que se ajustan a tu organización. Los marcos cubren aprobación, monitoreo y responsabilidad.",
    "riskHeading": "Herramientas de Evaluación de Riesgos",
    "riskText": "Construimos marcos de evaluación de riesgos para proyectos de IA. Los equipos evalúan el riesgo antes del despliegue usando criterios claros.",
    "workflowHeading": "Flujos de Aprobación",
    "workflowText": "Diseñamos procesos de aprobación para despliegues de IA. Las partes interesadas revisan proyectos en niveles de riesgo apropiados.",
    "trainingHeading": "Capacitación en Gobernanza",
    "trainingText": "Capacitamos equipos en políticas y herramientas de gobernanza de IA. El personal entiende sus responsabilidades y cómo cumplir."
  },
  "higherEdSpokes": {
    "gradStudentIntegrity": {
      "heroHeading": "Integridad de Estudiantes de Posgrado en Entornos de IA",
      "heroSubheading": "Ayuda a los estudiantes de posgrado a mantener la integridad mientras usan herramientas de IA de manera responsable.",
      "contentPara": "Los estudiantes de posgrado enfrentan presión para usar herramientas de IA mientras cumplen con estándares de integridad. Capacitamos estudiantes en uso responsable de IA, les ayudamos a documentar sus procesos de trabajo y enseñamos a la facultad a evaluar resultados de aprendizaje cuando las herramientas de IA están involucradas. Los estudiantes aprenden a usar IA como ayuda de investigación sin comprometer su desarrollo intelectual."
    },
    "authorizedLLMs": {
      "heroHeading": "LLM Departamentales Autorizados",
      "heroSubheading": "Implementa modelos de IA seguros aprobados por el departamento que protegen los datos de los estudiantes y cumplen con los estándares de cumplimiento.",
      "contentPara": "Los departamentos necesitan herramientas de IA seguras que cumplan con los requisitos de FERPA y GDPR. Te ayudamos a implementar modelos de lenguaje aprobados dentro de los límites institucionales. Los estudiantes acceden a herramientas de IA sin exponer datos sensibles a terceros. Tu institución mantiene el control sobre el uso de IA mientras protege la privacidad."
    },
    "facultyLiteracy": {
      "heroHeading": "Programas de Alfabetización en IA para Facultad",
      "heroSubheading": "Capacita a la facultad para evaluar el trabajo estudiantil de manera efectiva en entornos de IA.",
      "contentPara": "La facultad necesita habilidades para evaluar el trabajo estudiantil cuando las herramientas de IA están involucradas. Proporcionamos capacitación sobre las limitaciones de detección de IA, métodos de evaluación basados en procesos y actualizaciones de diseño de tareas. La facultad gana confianza evaluando el trabajo y ayudando a los estudiantes a usar IA de manera responsable. La capacitación se alinea con tus políticas institucionales y requisitos de acreditación."
    },
    "trustCharter": {
      "heroHeading": "Carta de Confianza del Campus",
      "heroSubheading": "Construye marcos de integridad a nivel de campus que funcionen en todos los departamentos.",
      "contentPara": "Las instituciones necesitan estándares de integridad consistentes en todos los programas. Te ayudamos a desarrollar cartas de confianza a nivel de campus que se alineen con los requisitos de acreditación. Los rectores obtienen marcos que funcionan en todos los departamentos. Tu carta proporciona expectativas claras para estudiantes y facultad mientras cumple con los estándares institucionales."
    },
    "trustCurrency": {
      "heroHeading": "La Confianza como Moneda Institucional",
      "heroSubheading": "Posiciona la integridad académica como una ventaja competitiva para la inscripción y el financiamiento.",
      "contentPara": "La confianza se convierte en un activo de reclutamiento y recaudación de fondos. Ayudamos al liderazgo a comunicar marcos de integridad a estudiantes potenciales y donantes. Tu institución demuestra compromiso con los estándares académicos mientras adopta IA de manera responsable. Las credenciales de confianza diferencian tus programas en mercados competitivos."
    },
    "ethicsCurriculum": {
      "heroHeading": "Desarrollo de Currículo de Ética de IA",
      "heroSubheading": "Integra ética de IA en programas de posgrado con módulos de revisión crítica.",
      "contentPara": "Los programas de posgrado necesitan contenido de ética de IA que se ajuste a sus disciplinas. Diseñamos módulos curriculares sobre uso responsable de IA, evaluación crítica de resultados de IA y consideraciones éticas. La facultad integra ética en cursos existentes o construye módulos independientes. Los estudiantes desarrollan habilidades de pensamiento crítico sobre herramientas de IA."
    },
    "researchTools": {
      "heroHeading": "Herramientas de Integridad en Investigación",
      "heroSubheading": "Herramientas éticas para la transparencia y reproducibilidad en investigación.",
      "contentPara": "Los investigadores necesitan herramientas para mantener la integridad en el análisis de datos y la presentación de informes. Proporcionamos recursos de integridad en investigación que incluyen calculadoras de valores p y herramientas de detección de sesgo. Las universidades demuestran compromiso con prácticas de investigación transparentes. Las herramientas interactivas ayudan a los investigadores a identificar errores estadísticos comunes antes de la publicación."
    }
  },
  "contact": {
    "heroHeading": "Contáctanos",
    "heroSubheading": "Cuéntanos sobre tus necesidades. Responderemos en 24 horas.",
    "formHeading": "Enviar un Mensaje",
    "nameLabel": "Tu Nombre",
    "emailLabel": "Correo Electrónico",
    "messageLabel": "Mensaje",
    "submitButton": "Enviar Mensaje",
    "placeholder": "Formulario de contacto próximamente. Escríbenos a contact@geoverity.com"
  },
  "footer": {
    "copyright": "© 2026 GeoVerity. Todos los derechos reservados."
  }
}
